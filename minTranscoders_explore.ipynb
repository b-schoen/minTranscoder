{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8136c449-8445-45fd-8d23-358f6e639e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# note: same thing for REPL\n",
    "# note: we use this instead of magic because `black` will otherwise fail to format\n",
    "#\n",
    "# Enable autoreload to automatically reload modules when they change\n",
    "\n",
    "from IPython import get_ipython\n",
    "\n",
    "# do this so that formatter not messed up\n",
    "ipython = get_ipython()\n",
    "ipython.run_line_magic(\"load_ext\", \"autoreload\")\n",
    "ipython.run_line_magic(\"autoreload\", \"2\")\n",
    "\n",
    "# Import commonly used libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# graphics\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# type annotation\n",
    "import jaxtyping\n",
    "from jaxtyping import Float, Float32, Int64, jaxtyped\n",
    "from typeguard import typechecked as typechecker\n",
    "\n",
    "# more itertools\n",
    "import more_itertools as mi\n",
    "\n",
    "# itertools\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "# tensor manipulation\n",
    "import einops\n",
    "\n",
    "# automatically apply jaxtyping\n",
    "# %load_ext jaxtyping\n",
    "# %jaxtyping.typechecker typeguard.typechecked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1271761",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c57a2677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# load the device we'll use (GPU or MPS)\n",
    "device = transformer_lens.utils.get_device()\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3bb617d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bronsonschoen/minTranscoder/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# load our model\n",
    "model_name = \"gpt2-small\"\n",
    "model = transformer_lens.HookedTransformer.from_pretrained(\n",
    "    model_name,\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    refactor_factored_attn_matrices=True,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1587a55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'After', ' John', ' and', ' Mary', ' went', ' to', ' the', ' store', ',', ' John', ' gave', ' a', ' bottle', ' of', ' milk', ' to']\n",
      "Tokenized answer: [' Mary']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.09</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70.07</span><span style=\"font-weight: bold\">% Token: | Mary|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m18.09\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m70.07\u001b[0m\u001b[1m% Token: | Mary|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 18.09 Prob: 70.07% Token: | Mary|\n",
      "Top 1th token. Logit: 15.38 Prob:  4.67% Token: | the|\n",
      "Top 2th token. Logit: 15.35 Prob:  4.54% Token: | John|\n",
      "Top 3th token. Logit: 15.25 Prob:  4.11% Token: | them|\n",
      "Top 4th token. Logit: 14.84 Prob:  2.73% Token: | his|\n",
      "Top 5th token. Logit: 14.06 Prob:  1.24% Token: | her|\n",
      "Top 6th token. Logit: 13.54 Prob:  0.74% Token: | a|\n",
      "Top 7th token. Logit: 13.52 Prob:  0.73% Token: | their|\n",
      "Top 8th token. Logit: 13.13 Prob:  0.49% Token: | Jesus|\n",
      "Top 9th token. Logit: 12.97 Prob:  0.42% Token: | him|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Mary'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Mary'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sanity check with an example\n",
    "example_prompt = \"After John and Mary went to the store, John gave a bottle of milk to\"\n",
    "example_answer = \" Mary\"\n",
    "transformer_lens.utils.test_prompt(\n",
    "    example_prompt,\n",
    "    example_answer,\n",
    "    model,\n",
    "    prepend_bos=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54629d69",
   "metadata": {},
   "source": [
    "# Define Transcoder Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b3c8476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "\n",
    "from min_transcoder.transcoder import (\n",
    "    TranscoderResults,\n",
    "    TranscoderConfig,\n",
    "    Transcoder,\n",
    ")\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class TranscoderTrainingConfig:\n",
    "\n",
    "    # Name of the layer to hook into for feature extraction\n",
    "    hook_point: str\n",
    "    out_hook_point: str\n",
    "\n",
    "    batch_size: int = 32\n",
    "    num_epochs: int = 5\n",
    "    learning_rate: float = 1e-3\n",
    "\n",
    "    # Coefficient for L1 regularization\n",
    "    l1_coefficient: float = 0.01\n",
    "\n",
    "    @property\n",
    "    def hook_point_layer(self) -> int:\n",
    "        \"Parse out the hook point layer as int ex: 'blocks.8.ln2.hook_normalized' -> 8\"\n",
    "        return int(self.hook_point.split(\".\")[-2])\n",
    "\n",
    "\n",
    "class TranscoderLoss:\n",
    "    loss: Float[torch.Tensor, \"\"]\n",
    "    mse_loss: Float[torch.Tensor, \"\"]\n",
    "    l1_loss: Float[torch.Tensor, \"\"]\n",
    "\n",
    "\n",
    "def compute_loss(\n",
    "    cfg: TranscoderTrainingConfig,\n",
    "    mlp_out: Float[torch.Tensor, \"...\"],\n",
    "    results: TranscoderResults,\n",
    ") -> TranscoderLoss:\n",
    "\n",
    "    mse_loss_per_batch: Float[torch.Tensor, \"...\"] = (\n",
    "        torch.pow((results.transcoder_out - mlp_out.float()), 2)\n",
    "        / (mlp_out**2).sum(dim=-1, keepdim=True).sqrt()\n",
    "    )\n",
    "\n",
    "    mse_loss = mse_loss_per_batch.mean()\n",
    "\n",
    "    sparsity = torch.abs(results.hidden_activations).sum(dim=1).mean(dim=(0,))\n",
    "\n",
    "    l1_loss = cfg.l1_coefficient * sparsity\n",
    "\n",
    "    loss = mse_loss + l1_loss\n",
    "\n",
    "    return TranscoderLoss(loss=loss, mse_loss=mse_loss, l1_loss=l1_loss)\n",
    "\n",
    "\n",
    "transcoder_expansion_factor = 4\n",
    "\n",
    "# reference: https://github.com/jacobdunefsky/transcoder_circuits/blob/master/train_transcoder.py#L28\n",
    "#\n",
    "transcoder_cfg = TranscoderConfig(\n",
    "    d_in=model.cfg.d_model,\n",
    "    d_out=model.cfg.d_model,\n",
    "    # our transcoder has a hidden dimension of d_mlp * expansion factor\n",
    "    d_hidden=model.cfg.d_mlp * transcoder_expansion_factor,\n",
    "    dtype=model.cfg.dtype,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dafb9432",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcoder = Transcoder(cfg=transcoder_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1cbe0b",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eca90e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 10000/10000 [00:00<00:00, 104130.77 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "\n",
    "dataset = datasets.load_dataset(\n",
    "    path=\"NeelNanda/pile-10k\",\n",
    "    split=\"train\",\n",
    "    streaming=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a26733ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (229134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Map: 100%|██████████| 10000/10000 [00:16<00:00, 607.32 examples/s]\n"
     ]
    }
   ],
   "source": [
    "token_dataset = transformer_lens.utils.tokenize_and_concatenate(\n",
    "    dataset=dataset,\n",
    "    tokenizer=model.tokenizer,\n",
    "    streaming=True,\n",
    "    max_length=model.cfg.n_ctx,\n",
    "    add_bos_token=model.cfg.default_prepend_bos,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef8569ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16957, 1024])\n"
     ]
    }
   ],
   "source": [
    "# torch.Size([16957, 1024])\n",
    "print(token_dataset[\"tokens\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285d87e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bdd288a",
   "metadata": {},
   "source": [
    "# Train Transcoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad3f53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "training_cfg = TranscoderTrainingConfig(\n",
    "    batch_size=32,\n",
    "    num_epochs=5,\n",
    "    learning_rate=1e-3,\n",
    "    # \"hook_point\" is the TransformerLens HookPoint representing\n",
    "    #    the input activations to the transcoder that we want to train on.\n",
    "    # Here, \"ln2.hook_normalized\" refers to the activations after the\n",
    "    #    pre-MLP LayerNorm -- that is, the inputs to the MLP.\n",
    "    # You might alternatively prefer to train on \"blocks.8.hook_resid_mid\",\n",
    "    #    which corresponds to the input to the pre-MLP LayerNorm.\n",
    "    hook_point=\"blocks.8.ln2.hook_normalized\",\n",
    "    # \"out_hook_point\" is the TransformerLens HookPoint representing\n",
    "    #    the output activations that the transcoder should reconstruct.\n",
    "    # In our use case, we're using transcoders to interpret MLP sublayers.\n",
    "    # This means that our transcoder will take in the input to an MLP and\n",
    "    #    attempt to spit out the output of the MLP (but in the form of a\n",
    "    #    sparse linear combination of feature vectors).\n",
    "    # As such, we want to grab the \"hook_mlp_out\" activations from our\n",
    "    #    transformer, which (as the name suggests), represent the\n",
    "    #    output activations of the original MLP sublayer.\n",
    "    out_hook_point=\"blocks.8.hook_mlp_out\",\n",
    ")\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "#\n",
    "# for batch in dataloader:\n",
    "#     print(batch.shape) # torch.Size([32, 1024])\n",
    "#     break\n",
    "#\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    token_dataset[\"tokens\"],\n",
    "    batch_size=training_cfg.batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "403769bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25600, 128)\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = torch.optim.AdamW(transcoder.parameters(), lr=training_cfg.learning_rate)\n",
    "\n",
    "# TODO(bschoen): Learning rate scheduler\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(training_cfg.num_epochs):\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    # Do a training step.\n",
    "    transcoder.train()\n",
    "\n",
    "    # Make sure the W_dec is still zero-norm\n",
    "    transcoder.set_decoder_norm_to_unit_norm()\n",
    "\n",
    "    for batch in tqdm.tqdm(\n",
    "        dataloader, desc=f\"Epoch {epoch+1}/{training_cfg.num_epochs}\"\n",
    "    ):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # move batch to device\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        # Get MLP input and output activations\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # TODO(bschoen): Is it faster to just run with cache and extract?\n",
    "            _, cache = model.run_with_cache(batch)\n",
    "\n",
    "        mlp_in = cache[training_cfg.hook_point]\n",
    "        mlp_out = cache[training_cfg.out_hook_point]\n",
    "\n",
    "        # Forward pass through transcoder\n",
    "        transcoder_results = transcoder(mlp_in)\n",
    "\n",
    "        # Compute loss\n",
    "        loss_result = compute_loss(training_cfg, mlp_out, transcoder_results)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss_result.loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss_result.loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    # Print epoch statistics\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Epoch {epoch+1}/{training_cfg.num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8074e379",
   "metadata": {},
   "source": [
    "# Compute Loss When Substituting MLP with Transcoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d46b6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_test_loss_when_replacing_mlp_with_transcoder(\n",
    "    self,\n",
    "    batch_tokens: Float[torch.Tensor, \"batch seq\"],\n",
    "    transcoder: Transcoder,\n",
    "    model: transformer_lens.HookedTransformer,\n",
    ") -> Float[torch.Tensor, \"\"]:\n",
    "    \"\"\"\n",
    "    A method for running the model with the SAE activations in order to return the\n",
    "    loss returns per token loss when activations are substituted in.\n",
    "\n",
    "    \"\"\"\n",
    "    old_mlp = model.blocks[self.cfg.hook_point_layer]\n",
    "\n",
    "    class TranscoderWrapper(torch.nn.Module):\n",
    "        def __init__(self, transcoder: Transcoder):\n",
    "            super().__init__()\n",
    "            self.transcoder = transcoder\n",
    "\n",
    "        def forward(\n",
    "            self,\n",
    "            x: Float[torch.Tensor, \"... d_in\"],\n",
    "        ) -> Float[torch.Tensor, \"... d_out\"]:\n",
    "            return self.transcoder(x)[0]\n",
    "\n",
    "    model.blocks[self.cfg.hook_point_layer].mlp = TranscoderWrapper(self)\n",
    "    ce_loss_with_recons = model.run_with_hooks(batch_tokens, return_type=\"loss\")\n",
    "    model.blocks[self.cfg.hook_point_layer] = old_mlp\n",
    "\n",
    "    return ce_loss_with_recons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2ef88d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e87ea8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7427f714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
